{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_anime_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1c-81PWEIa4",
        "colab_type": "code",
        "outputId": "e5787991-ac22-4b58-8550-d8ad94e08a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLwVuGXeEYJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "\n",
        "\n",
        "tar = tarfile.open(\"drive/My Drive/data.tgz\", \"r:gz\")\n",
        "tar.extractall(path=\"./dataset\")\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2K4IYXwEbCD",
        "colab_type": "code",
        "outputId": "cbab3bf6-f99f-4e81-9c6f-175c928bd25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import numpy as np \n",
        "from matplotlib import pyplot as p\n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "from keras.layers import Dense, Reshape, Conv2D, Conv2DTranspose, LeakyReLU , BatchNormalization, Input, Activation, Flatten\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "from PIL import Image \n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2ATUkDPdnEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "\n",
        "class ImageHelper(object):\n",
        "    def save_image(self, generated, epoch, directory):\n",
        "        fig, axs = p.subplots(5, 5)\n",
        "        count = 0\n",
        "        for i in range(5):\n",
        "            for j in range(5):\n",
        "                axs[i,j].imshow(generated[count, :,:,:])\n",
        "                axs[i,j].axis('off')\n",
        "                count += 1\n",
        "        fig.savefig(\"{}/{}.png\".format(directory, epoch))\n",
        "        p.close()\n",
        "        \n",
        "    def makegif(self, directory):\n",
        "        filenames = np.sort(os.listdir(directory))\n",
        "        filenames = [ fnm for fnm in filenames if \".png\" in fnm]\n",
        "    \n",
        "        with imageio.get_writer(directory + '/image.gif', mode='I') as writer:\n",
        "            for filename in filenames:\n",
        "                image = imageio.imread(directory + filename)\n",
        "                writer.append_data(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12yDQBWNJk_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = []\n",
        "\n",
        "pth = \"dataset/cropped/\"\n",
        "\n",
        "l = len(os.listdir(pth))\n",
        "k = 0\n",
        "\n",
        "for i in os.listdir(pth) : \n",
        "  \n",
        "   try : \n",
        "    k = k + 1 \n",
        "    print(\"{}%\".format(k*100//l))\n",
        "\n",
        "    x_train.append(np.asarray(Image.open(pth+i).resize((32,32),Image.ANTIALIAS))/255.0)\n",
        "   \n",
        "   except : \n",
        "      print(\"err\")\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdEXgubDMLlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.asarray(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKPejDMQF8EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dcgan : \n",
        "  \n",
        "  def __init__(self,img_shape,noise_shape,x_train) : \n",
        "    \n",
        "    self.img_shape = img_shape\n",
        "    self.img_w = img_shape[0]\n",
        "    self.img_h = img_shape[1]\n",
        "    self.channels = img_shape[2]\n",
        "    \n",
        "    self.latent_size = 100  \n",
        "    \n",
        "    self.x_train = np.reshape(x_train,(-1,self.img_w,self.img_h,self.channels))\n",
        "    \n",
        "    self.batch_size = 64\n",
        "    \n",
        "    #build discriminator\n",
        "    \n",
        "    self.discriminator = self.build_discriminator()\n",
        "    \n",
        "    optimizer = RMSprop(lr=2e-4,decay=6e-8)\n",
        "    self.discriminator.compile(optimizer=optimizer,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "    \n",
        "    plot_model(self.discriminator,show_shapes=True)\n",
        "    \n",
        "    #build generator\n",
        "    \n",
        "    self.generator = self.build_generator()\n",
        "    \n",
        "    plot_model(self.generator,show_shapes=True)\n",
        "    \n",
        "    #build dcgan\n",
        "    lr = 2e-4\n",
        "    decay = 6e-8\n",
        "    \n",
        "    optimizer = RMSprop(lr=lr*0.5,decay=decay*0.5)\n",
        "    \n",
        "    self.discriminator.trainable = False\n",
        "    input = Input(shape=(self.latent_size,),name=\"generator_input\")\n",
        "    self.model = Model(input,self.discriminator(self.generator(input)),name=\"dcgan\")\n",
        "    self.model.compile(optimizer=optimizer,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "    \n",
        "    plot_model(self.model)\n",
        "    \n",
        "  def build_generator(self) : \n",
        "    \n",
        "    input = Input(shape=(self.latent_size,),name=\"generator_input\")\n",
        "    \n",
        "    x = Dense(np.prod(self.img_shape))(input)\n",
        "    x = Reshape(self.img_shape)(x)\n",
        "    x = Conv2DTranspose(128,kernel_size=(5,5),strides=1,padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2DTranspose(64,kernel_size=(5,5),strides=1,padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2DTranspose(32,kernel_size=(5,5),strides=1,padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2DTranspose(3,kernel_size=(5,5),strides=1,padding=\"same\")(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "    \n",
        "    generator = Model(input,x,name=\"generator\")\n",
        "    \n",
        "    return generator\n",
        "  \n",
        "  def build_discriminator(self) : \n",
        "    \n",
        "    input = Input(shape=self.img_shape,name=\"discriminator_input\")\n",
        "    \n",
        "    x = Conv2D(32,kernel_size=(5,5),strides=2,padding=\"same\")(input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(64,kernel_size=(5,5),strides=2,padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(128,kernel_size=(5,5),strides=2,padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Conv2D(256,kernel_size=(5,5),strides=1,padding=\"same\")(input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "    \n",
        "    discriminator = Model(input,x,name=\"discriminator\")\n",
        "    \n",
        "    return discriminator\n",
        "  \n",
        "  def train(self) : \n",
        "    \n",
        "    train_noise = np.random.uniform(-1.0,1.0,size=[16,self.latent_size])\n",
        "    \n",
        "    train_size = self.x_train.shape[0]\n",
        "    \n",
        "    for i in range(10000) : \n",
        "      \n",
        "      #train discriminator\n",
        "      rand_indexs = np.random.randint(0,train_size,size=self.batch_size)\n",
        "      noise = np.random.uniform(-1.0,1.0,size=[self.batch_size,self.latent_size])\n",
        "      \n",
        "      real_images = self.x_train[rand_indexs]\n",
        "      fake_images = self.generator.predict(noise)\n",
        "      #real+fake images = 1 batch of train\n",
        "      x = np.concatenate((real_images,fake_images))\n",
        "      y = np.ones([2*self.batch_size,1])\n",
        "      y[self.batch_size:,:] = 0.0\n",
        "      loss, acc = self.discriminator.train_on_batch(x,y)\n",
        "      log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
        "      \n",
        "      #train the model\n",
        "      \n",
        "      noise = np.random.uniform(-1.0,1.0,size=[self.batch_size,self.latent_size])\n",
        "      y = np.ones([self.batch_size,1])\n",
        "      \n",
        "      \n",
        "      loss, acc = self.model.train_on_batch(noise,y)\n",
        "\n",
        "      log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
        "      print(log)\n",
        "      \n",
        "      if (i + 1) % 100 == 0:\n",
        "        if (i + 1) == 40000:\n",
        "          show = True\n",
        "        else:\n",
        "          show = False\n",
        "        \n",
        "        self.sample_images(i)\n",
        "\n",
        "     \n",
        "     \n",
        "    self.generator.save(\"./drive/My Drive/dcgan_generator_anime.h5\")\n",
        "\n",
        "  def sample_images(self, epoch):\n",
        "      r, c = 5, 5\n",
        "      noise = np.random.uniform(-1.0,1.0, (r * c, self.latent_size))\n",
        "      gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "      # Rescale images 0 - 1\n",
        "      gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "      fig, axs = p.subplots(r, c)\n",
        "      cnt = 0\n",
        "      for i in range(r):\n",
        "          for j in range(c):\n",
        "              axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "              axs[i,j].axis('off')\n",
        "              cnt += 1\n",
        "      fig.savefig(\"./im/%d.png\" % epoch)\n",
        "      p.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFhiXi3yI-KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dcgan = dcgan((32,32,3),100,x_train)\n",
        "\n",
        "dcgan.train(dcgan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8kL4rc7Us0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dcgan.generator.save(\"./drive/My Drive/dcgan_generator_anime.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}